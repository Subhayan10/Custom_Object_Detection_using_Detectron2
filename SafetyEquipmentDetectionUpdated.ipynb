{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O5_FvOd7x18"
      },
      "source": [
        "# TRAINING **CODE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhbS5C4Ks9bZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Install dependencies\n",
        "!pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# Import libraries\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# Define dataset paths\n",
        "SAVE_PATH = \"/content/drive/MyDrive/Dataset/SafetyEquipment\"\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Download dataset\n",
        "!curl -L \"https://universe.roboflow.com/ds/CmwBTV2FCH?key=wfRQPKfam9\" > safety_dataset.zip\n",
        "!unzip safety_dataset.zip -d {SAVE_PATH}\n",
        "!rm safety_dataset.zip\n",
        "\n",
        "# Register dataset\n",
        "DATASET_PATH = f\"{SAVE_PATH}/train/_annotations.coco.json\"\n",
        "TEST_PATH = f\"{SAVE_PATH}/valid/_annotations.coco.json\"\n",
        "\n",
        "register_coco_instances(\"safety_train\", {}, DATASET_PATH, f\"{SAVE_PATH}/train\")\n",
        "register_coco_instances(\"safety_valid\", {}, TEST_PATH, f\"{SAVE_PATH}/valid\")\n",
        "\n",
        "# Load metadata\n",
        "train_metadata = MetadataCatalog.get(\"safety_train\")\n",
        "dataset_dicts = DatasetCatalog.get(\"safety_train\")\n",
        "\n",
        "# Visualize sample images\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])\n",
        "\n",
        "# Configure model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"safety_train\",)\n",
        "cfg.DATASETS.TEST = (\"safety_valid\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "cfg.SOLVER.MAX_ITER = 5000\n",
        "cfg.SOLVER.STEPS = [3000, 4500]\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 25  # Adjust based on dataset\n",
        "cfg.OUTPUT_DIR = SAVE_PATH\n",
        "\n",
        "# Train model\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()\n",
        "\n",
        "# Save configuration\n",
        "with open(f\"{SAVE_PATH}/config.yml\", \"w\") as f:\n",
        "    f.write(cfg.dump())\n",
        "\n",
        "# Evaluate model\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "evaluator = COCOEvaluator(\"safety_valid\", output_dir=SAVE_PATH)\n",
        "val_loader = build_detection_test_loader(cfg, \"safety_valid\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "\n",
        "# Visualize test results\n",
        "for imageName in random.sample(os.listdir(f\"{SAVE_PATH}/valid\"), 5):\n",
        "    im = cv2.imread(os.path.join(f\"{SAVE_PATH}/valid\", imageName))\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1], metadata=train_metadata, scale=0.8)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCw8EBFJSZGa"
      },
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# Define evaluator\n",
        "evaluator = COCOEvaluator(\"safety_valid\", output_dir=SAVE_PATH)\n",
        "val_loader = build_detection_test_loader(cfg, \"safety_valid\")\n",
        "\n",
        "# Run evaluation\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGe9f2MRS7Bj"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load Dependencies\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Step 2: Load Trained Model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/Dataset/SafetyEquipment/config.yml\")  # Update path if needed\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Dataset/SafetyEquipment/model_final.pth\"  # Trained model path\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Confidence threshold\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Step 3: Upload Image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded image: {image_path}\")\n",
        "\n",
        "# Step 4: Load Image and Run Inference\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "outputs = predictor(image)\n",
        "\n",
        "# Step 5: Visualize Results\n",
        "v = Visualizer(image, MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "# Step 6: Display Image with Predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(out.get_image())\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Save the Output (Optional)\n",
        "output_filename = \"output.jpg\"\n",
        "cv2.imwrite(output_filename, cv2.cvtColor(out.get_image(), cv2.COLOR_RGB2BGR))\n",
        "print(f\"Result saved as {output_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ6BcGjMTKHp"
      },
      "outputs": [],
      "source": [
        "# Install Detectron2\n",
        "!pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# Step 1: Load Dependencies\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Step 2: Load Trained Model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/Dataset/SafetyEquipment/config.yml\")  # Update path if needed\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Dataset/SafetyEquipment/model_final.pth\"  # Trained model path\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Confidence threshold\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Step 3: Upload Image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded image: {image_path}\")\n",
        "\n",
        "# Step 4: Load Image and Run Inference\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "outputs = predictor(image)\n",
        "\n",
        "# Step 5: Visualize Results\n",
        "v = Visualizer(image, MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "# Step 6: Display Image with Predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(out.get_image())\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Save the Output (Optional)\n",
        "output_filename = \"output.jpg\"\n",
        "cv2.imwrite(output_filename, cv2.cvtColor(out.get_image(), cv2.COLOR_RGB2BGR))\n",
        "print(f\"Result saved as {output_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHP2zueX78h0"
      },
      "source": [
        "# TESTING **CODE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnbSQdf4_UcB"
      },
      "source": [
        "# **FOR IMAGES segmantation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl7_xvMgLPv3"
      },
      "outputs": [],
      "source": [
        "# Install Detectron2\n",
        "!pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# Import Required Libraries\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "# Load Trained Model Configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/Dataset/SafetyEquipment/config.yml\")\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Dataset/SafetyEquipment/model_final.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize Predictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Define Class Names\n",
        "class_names = [\n",
        "    'construction', 'Excavator', 'Gloves', 'Hardhat', 'Ladder', 'Mask', 'NO-Hardhat',\n",
        "    'NO-Mask', 'NO-Safety Vest', 'Person', 'SUV', 'Safety Cone', 'Safety Vest', 'bus',\n",
        "    'dump truck', 'fire hydrant', 'machinery', 'mini-van', 'sedan', 'semi', 'trailer',\n",
        "    'truck', 'truck and trailer', 'van', 'vehicle', 'wheel loader'\n",
        "]\n",
        "\n",
        "# Update Metadata with Class Names\n",
        "metadata = MetadataCatalog.get(\"safety_train\")\n",
        "metadata.thing_classes = class_names\n",
        "\n",
        "# Upload Image\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded image: {image_path}\")\n",
        "\n",
        "# Load Image and Run Inference\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "outputs = predictor(image)\n",
        "\n",
        "# Visualize Results with Class Names\n",
        "v = Visualizer(image, metadata, scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "# Display Image with Predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(out.get_image())\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Save the Output (Optional)\n",
        "output_filename = \"output.jpg\"\n",
        "cv2.imwrite(output_filename, cv2.cvtColor(out.get_image(), cv2.COLOR_RGB2BGR))\n",
        "print(f\"Result saved as {output_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awEEFf7d_cKE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import os\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Load Detectron2 Config and Model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/Dataset/SafetyEquipment/config.yml\")\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Dataset/SafetyEquipment/model_final.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize Predictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Define Class Names\n",
        "class_names = [\n",
        "    'construction', 'Excavator', 'Gloves', 'Hardhat', 'Ladder', 'Mask', 'NO-Hardhat',\n",
        "    'NO-Mask', 'NO-Safety Vest', 'Person', 'SUV', 'Safety Cone', 'Safety Vest', 'bus',\n",
        "    'dump truck', 'fire hydrant', 'machinery', 'mini-van', 'sedan', 'semi', 'trailer',\n",
        "    'truck', 'truck and trailer', 'van', 'vehicle', 'wheel loader'\n",
        "]\n",
        "\n",
        "# Update Metadata with Class Names\n",
        "metadata = MetadataCatalog.get(\"safety_train\")\n",
        "metadata.thing_classes = class_names\n",
        "\n",
        "# Load Video\n",
        "video_path = \"/content/drive/MyDrive/Dataset/SafetyEquipment/Construction2.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get Video Properties\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "print(f\"Video Loaded: {video_path}\")\n",
        "print(f\"FPS: {fps}, Width: {width}, Height: {height}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVgT_YID_mfM"
      },
      "outputs": [],
      "source": [
        "# Define output video path\n",
        "output_path = \"/content/drive/MyDrive/Dataset/SafetyEquipment/CONSTRUCTIONVIDEO_DETECTED2.mp4\"\n",
        "\n",
        "# Initialize Video Writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Process Video Frame by Frame\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Stop when video ends\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run Object Detection\n",
        "    outputs = predictor(frame_rgb)\n",
        "\n",
        "    # Visualize Detection Results\n",
        "    v = Visualizer(frame_rgb, metadata, scale=1.2)\n",
        "    out_frame = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\")).get_image()\n",
        "\n",
        "    # Convert RGB to BGR (for OpenCV)\n",
        "    out_frame_bgr = cv2.cvtColor(out_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Write Frame to Output Video\n",
        "    out.write(out_frame_bgr)\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 10 == 0:  # Print progress every 10 frames\n",
        "        print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "# Release Resources\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"Processing complete! Video saved at: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZW-5gInDjDM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Detectron2 Config and Model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/Dataset/SafetyEquipment/config.yml\")\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Dataset/SafetyEquipment/model_final.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize Predictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Define Class Names\n",
        "class_names = [\n",
        "    'construction', 'Excavator', 'Gloves', 'Hardhat', 'Ladder', 'Mask', 'NO-Hardhat',\n",
        "    'NO-Mask', 'NO-Safety Vest', 'Person', 'SUV', 'Safety Cone', 'Safety Vest', 'bus',\n",
        "    'dump truck', 'fire hydrant', 'machinery', 'mini-van', 'sedan', 'semi', 'trailer',\n",
        "    'truck', 'truck and trailer', 'van', 'vehicle', 'wheel loader'\n",
        "]\n",
        "\n",
        "# Update Metadata with Class Names\n",
        "metadata = MetadataCatalog.get(\"safety_train\")\n",
        "metadata.thing_classes = class_names\n",
        "\n",
        "# Load Video\n",
        "video_path = \"/content/drive/MyDrive/Dataset/SafetyEquipment/CONSTRUCTIONVIDEO.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get Video Properties\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define Output Video Path\n",
        "output_path = \"/content/drive/MyDrive/Dataset/SafetyEquipment/FINAL_OUTPUT.mp4\"\n",
        "\n",
        "# Initialize Video Writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Process Video Frame by Frame\n",
        "frame_count = 0\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(f\"Total Frames: {total_frames}, FPS: {fps}, Resolution: {width}x{height}\")\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Stop when video ends\n",
        "\n",
        "    # Convert BGR to RGB for Detectron2\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run Object Detection\n",
        "    outputs = predictor(frame_rgb)\n",
        "\n",
        "    # Visualize Detection Results\n",
        "    v = Visualizer(frame_rgb, metadata, scale=1.2)\n",
        "    out_frame = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\")).get_image()\n",
        "\n",
        "    # Convert RGB to BGR for OpenCV\n",
        "    out_frame_bgr = cv2.cvtColor(out_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Resize to ensure consistent frame size\n",
        "    out_frame_bgr = cv2.resize(out_frame_bgr, (width, height))\n",
        "\n",
        "    # Write Processed Frame to Output Video\n",
        "    out.write(out_frame_bgr)\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 10 == 0:  # Print progress every 10 frames\n",
        "        print(f\"Processed {frame_count}/{total_frames} frames...\")\n",
        "\n",
        "# Release Resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"Processing complete! Video saved at: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLTRah4rcAaO"
      },
      "source": [
        "# **For Object Tracking in Video**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn4zcPjhJhbS"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y opencv-python opencv-contrib-python numpy\n",
        "!pip install numpy==1.23.5 opencv-contrib-python==4.5.5.64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DbW9KPdYb_3G"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load Trained Model Configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/Dataset/SafetyEquipment/config.yml\")\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Dataset/SafetyEquipment/model_final.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize Predictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Define Class Names\n",
        "class_names = [\n",
        "    'construction', 'Excavator', 'Gloves', 'Hardhat', 'Ladder', 'Mask', 'NO-Hardhat',\n",
        "    'NO-Mask', 'NO-Safety Vest', 'Person', 'SUV', 'Safety Cone', 'Safety Vest', 'bus',\n",
        "    'dump truck', 'fire hydrant', 'machinery', 'mini-van', 'sedan', 'semi', 'trailer',\n",
        "    'truck', 'truck and trailer', 'van', 'vehicle', 'wheel loader'\n",
        "]\n",
        "\n",
        "# Update Metadata with Class Names\n",
        "metadata = MetadataCatalog.get(\"safety_train\")\n",
        "metadata.thing_classes = class_names\n",
        "\n",
        "# Upload Video\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded video: {video_path}\")\n",
        "\n",
        "# Open Video Capture\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "tracker = cv2.TrackerCSRT_create()  # Corrected tracker creation\n",
        "\n",
        "# Get Video Writer to save output\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"output.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "tracking_initialized = False\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    if not tracking_initialized:\n",
        "        outputs = predictor(frame_rgb)\n",
        "        instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "        if len(instances) > 0:\n",
        "            bbox = instances.pred_boxes.tensor[0].numpy()\n",
        "            x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2] - bbox[0]), int(bbox[3] - bbox[1])\n",
        "            tracker.init(frame, (x, y, w, h))\n",
        "            tracking_initialized = True\n",
        "    else:\n",
        "        success, bbox = tracker.update(frame)\n",
        "        if success:\n",
        "            x, y, w, h = [int(v) for v in bbox]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        else:\n",
        "            tracking_initialized = False  # Reinitialize if tracking fails\n",
        "\n",
        "    cv2_imshow(frame)  # Display frame in Colab\n",
        "    out.write(frame)  # Save to output video\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Tracking complete. Output saved as 'output.mp4'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5leVZ0q4p6x"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install deep-sort-realtime\n",
        "!pip install opencv-python\n",
        "!pip install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuwHx87W_u_w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ffmpeg\n",
        "from google.colab import files\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# Load Trained Model Configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/Dataset/SafetyEquipment/config.yml\")\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Dataset/SafetyEquipment/model_final.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize Predictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Define Class Names\n",
        "class_names = [\n",
        "    'construction', 'Excavator', 'Gloves', 'Hardhat', 'Ladder', 'Mask', 'NO-Hardhat',\n",
        "    'NO-Mask', 'NO-Safety Vest', 'Person', 'SUV', 'Safety Cone', 'Safety Vest', 'bus',\n",
        "    'dump truck', 'fire hydrant', 'machinery', 'mini-van', 'sedan', 'semi', 'trailer',\n",
        "    'truck', 'truck and trailer', 'van', 'vehicle', 'wheel loader'\n",
        "]\n",
        "\n",
        "# Update Metadata with Class Names\n",
        "metadata = MetadataCatalog.get(\"safety_train\")\n",
        "metadata.thing_classes = class_names\n",
        "\n",
        "# Upload Video\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded video: {video_path}\")\n",
        "\n",
        "# Open Video Capture\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get Video Properties\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Output Video\n",
        "output_path = \"veryFinalOutput.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Initialize DeepSORT Tracker\n",
        "tracker = DeepSort(max_age=50, n_init=3, nms_max_overlap=1.0)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Object Detection\n",
        "    outputs = predictor(frame_rgb)\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    if len(instances) > 0:\n",
        "        bboxes = instances.pred_boxes.tensor.numpy()\n",
        "        scores = instances.scores.numpy()\n",
        "        class_ids = instances.pred_classes.numpy()\n",
        "\n",
        "        # Format required for DeepSORT\n",
        "        detection_list = []\n",
        "        for i in range(len(bboxes)):\n",
        "            x1, y1, x2, y2 = map(int, bboxes[i])\n",
        "            detection_list.append(([x1, y1, x2, y2], scores[i], class_ids[i]))\n",
        "\n",
        "        # Update DeepSORT tracker\n",
        "        tracks = tracker.update_tracks(detection_list, frame=frame)\n",
        "\n",
        "        for track in tracks:\n",
        "            if track.is_confirmed():\n",
        "                track_id = track.track_id\n",
        "                x1, y1, x2, y2 = map(int, track.to_tlbr())\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, f'ID {track_id}', (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    cv2_imshow(frame)  # Display in Colab\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(\"Tracking complete. Output saved as 'output.mp4'.\")\n",
        "\n",
        "from google.colab import output\n",
        "output.clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4zUKMon5ANz"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Nf2GOi_819"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB7JTtKQWyeI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}